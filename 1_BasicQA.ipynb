{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682aa4bf",
   "metadata": {},
   "source": [
    "# Lesson 1 - Building a QA Agent with Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44948034",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    %% User / Client Layer\n",
    "    User([User / A2A Client])\n",
    "    \n",
    "    %% Main Orchestrator Layer (Lesson 8)\n",
    "    subgraph OrchestratorLayer [Router/Requirement Agent]\n",
    "        Concierge[\"<b>Healthcare Concierge Agent</b><br/>(BeeAI Framework)<br/><code>Port: 9996</code>\"]\n",
    "    end\n",
    "\n",
    "    subgraph SubAgents [A2A Agent Servers]\n",
    "        direction LR\n",
    "\n",
    "        PolicyAgent[\"<b>Policy Agent</b><br/>(Gemini with A2A SDK)<br/><code>Port: 9999</code>\"]\n",
    "        ResearchAgent[\"<b>Research Agent</b><br/>(Google ADK)<br/><code>Port: 9998</code>\"]\n",
    "\n",
    "        ProviderAgent[\"<b>Provider Agent</b><br/>(LangGraph + LangChain)<br/><code>Port: 9997</code>\"]\n",
    "    end\n",
    "\n",
    "    %% Data & Tools Layer\n",
    "    subgraph DataLayer [Data Sources & Tools]\n",
    "        PDF[\"Policy PDF\"]\n",
    "        Google[Google Search Tool]\n",
    "        MCPServer[\"FastMCP Server<br/>(<code>doctors.json</code>)\"]\n",
    "    end\n",
    "    \n",
    "    Label_UA[\"Sends Query - A2A\"]\n",
    "    Label_CP[\"A2A\"]\n",
    "    Label_CR[\"A2A\"]\n",
    "    Label_CProv[\"A2A\"]\n",
    "    Label_MCP[\"MCP (stdio)\"]\n",
    "\n",
    "    %% -- CONNECTIONS --\n",
    "    \n",
    "    User --- Label_UA --> Concierge\n",
    "\n",
    "    Concierge --- Label_CP --> PolicyAgent\n",
    "    Concierge --- Label_CR --> ResearchAgent\n",
    "    Concierge --- Label_CProv --> ProviderAgent\n",
    "    \n",
    "    PolicyAgent -- \"Reads\" --> PDF\n",
    "    ResearchAgent -- \"Calls\" --> Google\n",
    "    \n",
    "    ProviderAgent --- Label_MCP --> MCPServer\n",
    "\n",
    "    classDef orchestrator fill:#f9f,stroke:#333,stroke-width:2px;\n",
    "    classDef agent fill:#e1f5fe,stroke:#0277bd,stroke-width:2px;\n",
    "    classDef tool fill:#fff3e0,stroke:#ef6c00,stroke-width:1px,stroke-dasharray: 5 5;\n",
    "    \n",
    "    classDef protocolLabel fill:#ffffff,stroke:none,color:#000;\n",
    "    \n",
    "    class Concierge orchestrator;\n",
    "    class PolicyAgent,ResearchAgent,ProviderAgent agent;\n",
    "    class PDF,Google,MCPServer tool;\n",
    "    \n",
    "    class Label_UA,Label_CP,Label_CR,Label_CProv,Label_MCP protocolLabel;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdacf96b",
   "metadata": {},
   "source": [
    "In this lesson, you will build a basic Question Answering (QA) agent using Google's Gemini model via the Google Gemini API. You will use **LiteLLM** to interact with the model to analyze a PDF document containing health insurance policy details. Then, you will refactor this logic into a reusable Python class, laying the groundwork for the next lesson where you will wrap this agent in an Agent2Agent (A2A) server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894a7f4",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> ðŸ’» &nbsp; <b>To Access <code>requirements.txt</code> and the <code>data</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860fbdb",
   "metadata": {},
   "source": [
    "## 1.1. Import Libraries and Setup\n",
    "\n",
    "First, import the necessary libraries. You will use `litellm` to interact with the LLM and standard libraries to handle file encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6e09a-633d-4dd6-a3c8-bdcd6b4e3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import litellm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520ec7b-13c1-4efc-b386-6ccecaa0723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd488a",
   "metadata": {},
   "source": [
    "## 1.2. Load and Encode Data\n",
    "\n",
    "You read the insurance policy PDF (`2026AnthemgHIPSBC.pdf`) and encode it in base64 so it can be passed to the model as context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dadf2-2825-463d-a7b6-657e54429dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"../data/2026AnthemgHIPSBC.pdf\").open(\"rb\") as file:\n",
    "    pdf_data = base64.standard_b64encode(file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84422142",
   "metadata": {},
   "source": [
    "## 1.3. Query the Model\n",
    "\n",
    "Now you will send a specific query to the model: \"How much would I pay for mental health therapy?\". You provide the model with a system instruction to act as an expert insurance agent and pass the PDF document alongside the user's text prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2682ba-6ea6-4d6c-8955-dedfa892a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How much would I pay for mental health therapy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a15ab1-93b0-4c70-bc4f-743e6a53f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert insurance agent designed to assist with coverage queries. Use the provided documents to answer questions about insurance policies. If the information is not available in the documents, respond with 'I don't know'\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:application/pdf;base64,{pdf_data}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a72ed-3444-46ac-a4b5-600c378b70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.choices[0].message.content.replace(\"$\", r\"\\\\$\")\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c9e25",
   "metadata": {},
   "source": [
    "## 1.4. Refactor into an Agent Class\n",
    "\n",
    "To make this code reusable and easier to integrate into an A2A server later, you will wrap the logic into a `PolicyAgent` class in a file named `policy_agent.py`. This class initializes the data in the `__init__` method and exposes an `answer_query` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43d6da-63b3-487e-8677-883e5ec7c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile policy_agent.py\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import litellm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class PolicyAgent:\n",
    "    def __init__(self) -> None:\n",
    "        load_dotenv()\n",
    "        with Path(\"../data/2026AnthemgHIPSBC.pdf\").open(\"rb\") as file:\n",
    "            self.pdf_data = base64.standard_b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "    def answer_query(self, prompt: str) -> str:\n",
    "        response = litellm.completion(\n",
    "            model=\"gemini/gemini-2.0-flash\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert insurance agent designed to assist with coverage queries. Use the provided documents to answer questions about insurance policies. If the information is not available in the documents, respond with 'I don't know'\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:application/pdf;base64,{self.pdf_data}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.replace(\"$\", r\"\\\\$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d8187",
   "metadata": {},
   "source": [
    "## 1.5. Test the Agent Class\n",
    "\n",
    "Finally, import the `PolicyAgent` class you just created and test it with the same query to ensure it works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d8e65-c99d-44ac-b954-269907a88210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from policy_agent import PolicyAgent\n",
    "\n",
    "print(\"Running Health Insurance Policy Agent\")\n",
    "agent = PolicyAgent()\n",
    "prompt = \"How much would I pay for mental health therapy?\"\n",
    "\n",
    "response = agent.answer_query(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d2075",
   "metadata": {},
   "source": [
    "## 1.6. Resources\n",
    "\n",
    "- [Google Gemini API Documentation](https://ai.google.dev/docs)\n",
    "- [LiteLLM Documentation](https://docs.litellm.ai/docs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92c98c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb038a8-fca4-4d6c-b937-79d4e4502074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c8ee7-c78b-4fea-8eb0-6fe7275243e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
